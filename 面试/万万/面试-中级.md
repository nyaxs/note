#Netty
> 1) API 使用简单，开发门槛低；
> 2) 功能强大，预置了多种编解码功能，支持多种主流协议；
> 3) 定制能力强，可以通过 ChannelHandler 对通信框架进行灵活的扩展；
> 4) 性能高，通过与其它 NIO 框架对比，Netty 的综合性能最优；
> 5) 成熟、稳定，Netty 修复了已经发现的所有 JDK NIO BUG
> 6) 社区活跃，版本迭代周期短，发现的 BUG 可以被及时修复，同时，更多的新功能会被
     加入；

###原生的 NIO 在 JDK 1.7 版本存在 epoll bug
> 它会导致 Selector 空轮询，最终导致 CPU 100%。

###什么是 TCP 粘包/拆包
> 1、要发送的数据大于缓冲区剩余空间大小，将会发生拆包。      
> 2、待发送数据大于 MSS（最大报文长度），传输前将进行拆包。    
> 3、要发送的数据小于发送缓冲区的大小，将多次写入缓冲区的数据一次发送出去，将会发生粘包。      
> 4、应用层没有及时读取接收缓冲区中的数据，将发生粘包。    

###bio与nio的区别
1、bio同步阻塞io：进程发起IO操作以后，必须等待IO操作的完成。JAVA传统的IO模型属于此种⽅式！即使用线程池也不行,万一线程太多,上下文切换资源占太多性能损耗      
2、nio同步⾮阻塞式I/O；java NIO采⽤了双向通道进⾏数据传输，通道上的事件：连接事件、读写事件；
NIO主要有三⼤核⼼部分：Channel(通道)，Buffer(缓冲区), Selector。传统IO基于字节流和字符流进⾏操作，⽽NIO基于Channel和
Buffer(缓冲区)进⾏操作，数据总是从通道读取到缓冲区中，或者从缓冲区写⼊到通道中。Selector(选择区)⽤于监听多个通道的事件
（⽐如：连接打开，数据到达）。单个线程可以监听多个数据通道。
1. BIO （Blocking I/O）：同步阻塞I/O模式，数据的读取写⼊必须阻塞在⼀个线程内等待其完成,⼀个线程停留在⼀个⽔壶那，直到这个⽔壶烧开
2. NIO （New I/O）：同时⽀持阻塞与⾮阻塞模式，什么叫做同步⾮阻塞？线程不断的轮询每个⽔壶的状态，看看是否有⽔壶的状态发⽣了改变，从⽽进⾏下⼀步的操作
3. AIO （ Asynchronous I/O）：异步⾮阻塞I/O模型。异步⾮阻塞与同步⾮阻塞的区别？异步⾮阻塞⽆需⼀个线程去轮询所有
IO操作的状态改变，在相应的状态改变后，系统会通知对应的线程来处理。为每个⽔壶上⾯装了⼀个开关，⽔
烧开之后，⽔壶会⾃动通知我⽔烧开了。


###select与poll的区别
1、io多路复⽤：       
1、概念：IO多路复⽤是指内核⼀旦发现进程指定的⼀个或者多个IO条件准备读取，它就通知该进程。     
2、优势：与多进程和多线程技术相⽐，I/O多路复⽤技术的最⼤优势是系统开销⼩，系统不必创建进程/线程，也不必维护这些进         
程/线程，从⽽⼤⼤减⼩了系统的开销。          
3、系统：⽬前⽀持I/O多路复⽤的系统调⽤有 select，pselect，poll，epoll。 2、select：select⽬前⼏乎在所有的平台上⽀持，其良好跨平台⽀持也是它的⼀个优点。select的⼀个缺点在于单个进程能够监视的          
⽂件描述符的数量存在最⼤限制，在Linux上⼀般为1024，可以通过修改宏定义甚⾄重新编译内核的⽅式提升这⼀限制，但是这样也          
会造成效率的降低。           
3、poll：它没有最⼤连接数的限制，原因是它是基于链表来存储的，但是同样有⼀个缺点：         
a. ⼤量的fd的数组被整体复制于⽤户态和内核地址空间之间，⽽不管这样的复制是不是有意义。       
b. poll还有⼀个特点是“⽔平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。      
epoll跟select都能提供多路I/O复⽤的解决⽅案。在现在的Linux内核⾥有都能够⽀持，其中epoll是Linux所特有，⽽select则应该是        
POSIX所规定，⼀般操作系统均有实现。        

###TCP和UDP的区别，TCP为什么是三次握手，不是两次。
1. TCP建⽴连接的过程。
   三次握⼿：
1. 第⼀次握⼿(客户端发送syn包到服务器端)：客户端发送syn包到服务
   器端，进⼊syn_send状态，等待服务器端的确认；
2. 第⼆次握⼿(服务器返回syn+ack包给客户端)：服务器端收到客户端
   的syn包，发送syn+ack包给客户端，进⼊syn_recv状态；
3. 第三次握⼿(客服端返回ack包给服务端)：客户端收到服务器端的
   syn+ack包，发送个ack包到服务器端，⾄此，客户端与服务器端进⼊
   established状态；
4. 握⼿过程中传送的包不包含任何数据，连接建⽴后才会开始传送数
   据，理想状态下，TCP连接⼀旦建⽴，在通信双⽅的任何⼀⽅主动关闭
   连接前，TCP连接都会⼀直保持下去。
2. TCP断开连接的过程。
   四次挥⼿：
1. 第⼀次挥⼿：主动关闭⽅发送fin包到被动关闭⽅，告诉被动关闭⽅我
   不会再给你发送数据了；
2. 第⼆次挥⼿：被动关闭⽅收到syn包，发送ack给对⽅，确认序号为收
   到序号+1；
3. 第三次挥⼿：被动关闭⽅也也发送fin包给主动关闭⽅，告诉对⽅我也
   不会给你发送数据了；
4. 第四次挥⼿：主动关闭⽅收到syn包，发送ack给对⽅，⾄此，完成四
   次挥⼿；

###什么是中间件？
中间件是处于操作系统和应用程序之间软件，使用时旺旺是一组中间件集成在一起，构成一个平台（开发平台+运行平台），在这组中间件中必须要有一个通信中间件，即中间件= 平台+通信    
主要分类：远程过程调用、面向消息的中间件、对象请求代理、事物处理监控。

#dubbo

###分布式框架dubbo的好处，不⽤dubbo可不可以。为什么要使⽤分布式
1、dubbo好处：      
1、远程通讯: 提供对多种基于⻓连接的NIO框架抽象封装， 包括多种线程模型，序列化，以及“请求-响应”模式的信息交换⽅        
式。      
2、软负载均衡及容错机制: 提供基于接⼝⽅法的透明远程过程调⽤，包括多协议⽀持，以及软负载均衡，失败容错，地址路由，      
动态配置等集群⽀持。可在内⽹替代F5等硬件负载均衡器，降低成本，减少单点。     
3、服务⾃动注册与发现: 基于注册中⼼⽬录服务，使服务消费⽅能动态的查找服务提供⽅，使地址透明，使服务提供⽅可以平滑      
增加或减少机器 。   
4、提供完善的管理控制台dubbo-admin与简单的控制中⼼dubbo-monitor      
5、Dubbo提供了伸缩性很好的插件模型，很⽅便进⾏扩展（ExtensionLoader） 2、不⽤dubbo可不可以：可以，使⽤springcloud。 3、分布式作⽤：      
a. 系统之间的耦合度⼤⼤降低，可以独⽴开发、独⽴部署、独⽴测试，系统与系统之间的边界⾮常明确，排错也变得相当容易，      
开发效率⼤⼤提升。   
b. 系统之间的耦合度降低，从⽽系统更易于扩展。我们可以针对性地扩展某些服务。假设这个商城要搞⼀次⼤促，下单量可能会      
⼤⼤提升，因此我们可以针对性地提升订单系统、产品系统的节点数量，⽽对于后台管理系统、数据分析系统⽽⾔，节点数量维        
持原有⽔平即可。                
c. 服务的复⽤性更⾼。⽐如，当我们将⽤户系统作为单独的服务后，该公司所有的产品都可以使⽤该系统作为⽤户系统，⽆需重复开发。       

###rpc和http的区别，使⽤场景？
a. 区别：      
传输协议     
RPC，可以基于TCP协议，也可以基于HTTP协议     
HTTP，基于HTTP协议     
传输效率     
RPC，使⽤⾃定义的TCP协议，可以让请求报⽂体积更⼩，或者使⽤HTTP2协议，也可以很好的减少报⽂的体积，提     
⾼传输效率    
HTTP，如果是基于HTTP1.1的协议，请求中会包含很多⽆⽤的内容，如果是基于HTTP2.0，那么简单的封装以下是可    
以作为⼀个RPC来使⽤的，这时标准RPC框架更多的是服务治理            
性能消耗，主要在于序列化和反序列化的耗时    
RPC，可以基于thrift实现⾼效的⼆进制传输      
HTTP，⼤部分是通过json来实现的，字节⼤⼩和序列化耗时都⽐thrift要更消耗性能    
负载均衡     
RPC，基本都⾃带了负载均衡策略     
HTTP，需要配置Nginx，HAProxy来实现     
服务治理（下游服务新增，重启，下线时如何不影响上游调⽤者）    
RPC，能做到⾃动通知，不影响上游    
HTTP，需要事先通知，修改Nginx/HAProxy配置    
b. 总结：RPC主要⽤于公司内部的服务调⽤，性能消耗低，传输效率⾼，服务治理⽅便。HTTP主要⽤于对外的异构环境，浏览      
器接⼝调⽤，APP接⼝调⽤，第三⽅接⼝调⽤等。    

###分布式事务如何保持⼀致性？



###接⼝限流⽅案
1. 限制 总并发数（⽐如 数据库连接池、线程池）
2. 限制 瞬时并发数（如 nginx 的 limit_conn 模块，⽤来限制 瞬时并发连接数）
3. 限制 时间窗⼝内的平均速率（如 Guava 的 RateLimiter、nginx 的 limit_req 模块，限制每秒的平均速率）
4. 限制 远程接⼝ 调⽤速率
5. 限制 MQ 的消费速率
6. 可以根据 ⽹络连接数、⽹络流量、CPU 或 内存负载 等来限流

###hashmap的扩容过程
会判断当前容器的元素个数，如果大于等于阈值,即当前数组的长度乘以加载因子的值的时候，就要自动扩容

###ConcurrentHashMap使⽤原理
1、⼯作机制（分⽚思想）：它引⼊了⼀个“分段锁”的概念，具体可以理解为把⼀个⼤的Map拆分成N个⼩的segment，根据key.hashCode()    
来决定把key放到哪个HashTable中。可以提供相同的线程安全，但是效率提升N倍，默认提升16倍。      
2、应⽤：当读>写时使⽤，适合做缓存，在程序启动时初始化，之后可以被多个线程访问；    
3、hash冲突：      
1、简介：HashMap中调⽤hashCode()⽅法来计算hashCode。由于在Java中两个不同的对象可能有⼀样的hashCode,所以不同的键可     
能有⼀样hashCode，从⽽导致冲突的产⽣。    
2、hash冲突解决：使⽤平衡树来代替链表，当同⼀hash中的元素数量超过特定的值便会由链表切换到平衡树     
4、⽆锁读：ConcurrentHashMap之所以有较好的并发性是因为ConcurrentHashMap是⽆锁读和加锁写，并且利⽤了分段锁（不是在所有的    
entry上加锁，⽽是在⼀部分entry上加锁）；     
读之前会先判断count(jdk1.6)，其中的count是被volatile修饰的(当变量被volatile修饰后，每次更改该变量的时候会将更改结果写到       
系统主内存中，利⽤多处理器的缓存⼀致性，其他处理器会发现⾃⼰的缓存⾏对应的内存地址被修改，就会将⾃⼰处理器的缓存⾏设置为失效，并强制      
从系统主内存获取最新的数据。)，故可以实现⽆锁读。   

###dubbo和dubbox之间的区别？
答：Dubbox 和Dubbo本质上没有区别，名字的含义扩展了Dubbo而已，以下扩展出来的功能      

###dubbox和spring cloud区别?

###dubbox的源码看过没,dubbox有哪些组件,介绍下?

###如果叫你自己设计一个中间件,你会如何设计?
我会从以下几点方面考虑开发：  
1)远程过程调用    
2)面向消息：利用搞笑的消息传递机制进行平台无关的数据交流，并给予数据通信来进行分布式系统的集成，有一下三个特点：   
i)通讯程序可以在不同的时间运行    
ii)通讯晨旭之家可以一对一、一对多、多对一甚至是上述多种方式的混合  
iii)程序将消息放入消息队列会从小吸毒列中取出消息来进行通讯
3)对象请求代理：提供不同形式的通讯服务包括同步、排队、订阅发布、广播等。可构筑各种框架如：事物处理监控器、分布数据访问、对象事务管理器OTM等。   
4)事物处理监控有一下功能：  
a)进程管理，包括启动server进程、分配任务、监控其执行并对负载进行平衡  
b)事务管理，保证在其监控下的事务处理的原子性、一致性、独立性和持久性
c)通讯管理，为client和server之间提供多种通讯机制，包括请求响应、会话、排队、订阅发布和广播等

#算法
###用过哪些算法？选择其一进行具体说明，为何会使用该算法？

#并发编程
###并发编程三要素
原子性,可见性,有序性
###可见性的方法有哪些？
synchronized 或者 Lock：保证同一个时刻只有一个线程获取锁执行代码，锁释放之前把最 新的值刷新到主内存，实现可见性

###内存屏障与volatile：
1. 由于现代操作系统都是多处理器操作系统，每个处理器都会有⾃⼰的缓存，可能存再不同处理器缓存不⼀致的问题，⽽且由于操作   
   系统可能存在重排序，导致读取到错误的数据，因此，操作系统提供了⼀些内存屏障以解决这种问题。   
   LoadLoad屏障    
   对于Load1; LoadLoad; Load2 ，操作系统保证在Load2及后续的读操作读取之前，Load1已经读取。   
   StoreStore屏障   
   对于Store1; StoreStore; Store2 ，操作系统保证在Store2及后续的写操作写⼊之前，Store1已经写⼊。   
   LoadStore屏障   
   对于Load1; LoadStore; Store2，操作系统保证在Store2及后续写⼊操作执⾏前，Load1已经读取。   
   StoreLoad屏障   
   对于Store1; StoreLoad; Load2 ，操作系统保证在Load2及后续读取操作执⾏前，Store1已经写⼊，开销较⼤，但是同时具备其   
   他三种屏障的效果。   
2. 当我们声明某个变量为volatile时，这个变量便具有了线程可⻅性。volatile通过在读写操作前后添加内存屏障，完成了数据的及时   
   可⻅性。   
3.
当写⼊⼀个volatile变量时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存。
当读⼀个volatile变量时，JMM会把该线程对应的本地内存置为⽆效，从主内存中读取所有的共享变量。
4.
- volatile读之前，会添加LoadLoad内存屏障。
- volatile读之后，会添加LoadStore内存屏障。
- volatile写之前，会添加StoreStore内存屏障。
- volatile写之后，会添加StoreLoad型内存屏障。

###sychronized 和 ReentrantLock 的区别
（1）ReentrantLock 显示获得、释放锁，synchronized 隐式获得释放锁        
（2）ReentrantLock 可响应中断、可轮回，synchronized 是不可以响应中断的，为处理 锁的不可用性提供了更高的灵活性       
（3）ReentrantLock 是 API 级别的，synchronized 是 JVM 级别的        
（4）ReentrantLock 可以实现公平锁      
（5）ReentrantLock 通过 Condition 可以绑定多个条件    

###sychronized 的自旋锁、偏向锁、轻量级锁、重量级锁，分别介绍和联系 
自旋锁：果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁的线程就不 需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等（自旋），
等持有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核的切换的消耗。       
偏向锁：顾名思义，它会偏向于第一个访问锁的线程，如果在运行过程中，同步锁只 有一个线程访问，     
不存在多线程争用的情况，则线程是不需要触发同步的，减少加锁／解 锁 的一些 CAS 操作（比如等待队列的一些 CAS 操作），这种情况下，就会给线程加一个 偏向锁。     
如果在运行过程中，遇到了其他线程抢占锁，则持有偏向锁的线程会被挂起， JVM 会消除它身上的偏向锁，将锁恢复到标准的轻量级锁。      
轻量级锁：轻量级锁是由偏向所升级来的，偏向锁运行在一个线程进入同步块的情况 下，当第二个线程加入锁争用的时候，偏向锁就会升级为轻量级锁；     
重量级锁：我们知道，我们要进入一个同步、线程安全的方法时，是需要先获得这个 方法的锁的，退出这个方法时，则会释放锁。如果获取不到这个锁的话，意味着有别的线 程在执行这个方法，这时我们就会马上进入阻塞的状态，等待那个持有锁的线程释放锁， 然后再把我们从阻塞的状态唤醒，我们再去获取这个方法的锁。这种获取不到锁就马上进 入阻塞状态的锁，我们称之为重量级锁。

###CountDownLatch 与 CyclicBarrier 区别
![img.png](../面试Img/img.png)
（1）CountDownLatch 简单的说就是一个线程等待，直到他所等待的其他线程都执行完成并 且调用 countDown()方法发出通知后，当前线程才可以继续执行。      
（2）cyclicBarrier 是所有线程都进行等待，直到所有线程都准备好进入 await()方法之后， 所有线程同时开始执行！       
（3）CountDownLatch 的计数器只能使用一次。而 CyclicBarrier 的计数器可以使用 reset() 方法重置。所以 CyclicBarrier 能处理更为复杂的业务场景，比如如果计算发生错误，可以 重置计数器，并让线程们重新执行一次。          
（4）CyclicBarrier 还提 供其他有 用的方法 ，比如 getNumberWaiting 方法 可以获得 CyclicBarrier 阻塞的线程数量。isBroken 方法用来知道阻塞的线程是否被中断。如果被中断 返回 true，否则返回 false。      

###volatile 关键字的作用
保证可见性
也可以和 CAS 结合，保证了原子性,AtomicInteger

###什么是 CAS     
cas 是一种基于锁的操作，乐观锁。      
CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。      
如果内存地址 里面的值和 A 的值是一样的，那么就将内存里面的值更新成 B。    
CAS 是通过无限循环来获 取数据的，若果在第一轮循环中，a 线程获取地址里面的值被 b 线程修改了，      
那么 a 线程 需要自旋，到下次循环才有可能机会执行。   

###什么是自旋
比如synchronized 里面的代码执行得非常快，此时等待的线程 都加锁可能是一种不太值得的操作，因为线程阻塞涉及到用户态和内核态切换的问题
不妨让等待锁的线程不要被阻塞，而是在 synchronized 的边界做忙循环，这就是自旋

###Semaphore 有什么作用
Semaphore 就是一个信号量，它的作用是限制某段代码块的并发数。Semaphore 有一个构造 函数，可以传入一个 int 型整数 n， 
表示某段代码最多只有 n 个线程可以访问，如果超出 了 n，那么请等待，等到某个线程执行完毕这段代码块，下一个线程再进入。  
由此可以看出 如果 Semaphore 构造函数中传入的 int 型整数 n=1，相当于变成了一个 synchronized 了。 


###什么是 Future？
在并发编程中，我们经常用到非阻塞的模型，在之前的多线程的三种实现中，不管是继承 thread 类还是实现 runnable 接口，    
都无法保证获取到之前的执行结果。通过实现 Callback 接口，并用 Future 可以来接收多线程的执行结果。      
Future 表示一个可能还没有完成的异步任务的结果，针对这个结果可以添加 Callback 以便 在任务执行成功或失败后作出相应的操作。       
FutureTask 异步运算的任务 异步运算的任务的结果进行等待获取、判断是否已 经完成、取消任务等操作     

###AQS 抽象队列同步器详解
AQS 是 AbustactQueuedSynchronizer 的简称，它是一个 Java 提高的底层同步工具类，用一 个 int 类型的变量表示同步状态，并提供了一系列的 CAS 操作来管理这个同步状态。    
AQS 是一个用来构建锁和同步器的框架，使用 AQS 能简单且高效地构造出应用广泛的大量 的同步器，    
比如我们提到的 ReentrantLock，Semaphore，其他的诸如 ReentrantReadWriteLock， SynchronousQueue，FutureTask 等等皆是基于 AQS 的。     
（1）独占式   
（2）共享式   
这样方便使用者实现不同类型的同步组件，独占式如 ReentrantLock，共享式如 Semaphore， CountDownLatch，组 合 式 的 如 ReentrantReadWriteLock。      
总之，AQS 为使用提供了底层 支撑，如何组装实现，使用者可以自由发挥。   


###ReadWriteLock(读写锁) 是什么 
ReentrantLock(可重入锁) 某些时候有局限。如果用 ReentrantLock，可能本身是为了防止线程 A 在写数据、线程 B 在读数据造成的数据不 一致，
但这样，如果线程 C 在读数据、线程 D 也在读数据，读数据是不会改变数据的，没有必要加锁，但是还是加锁了，降低了程序的性能。
因为这个，才诞生了读写锁 ReadWriteLock . ReentrantReadWriteLock 是 ReadWriteLock 接口的一个具体实现，
实现了读写的分离，读锁是共享的，写锁是独占的， 读和读之间不会互斥，读和写、写和读、写和写之间才会互斥，提升了读写的性能。


###HashMap和ConcurrentHashMap的区别，以及两者的优缺点

###jdk1.7到jdk1.8 Map发生了什么变化(底层)
1.8之后hashMap的数据结构发生了变化，从之前的单纯的数组+链表结构变成数组+链表+红黑树。也就是说在JVM存储hashMap的K-V时仅仅通过key来决定每一个entry的存储槽位（Node[]中的index）。并且Value以链表的形式挂在到对应槽位上（1.8以后如果value长度大于8则转为红黑树）。   
但是hashmap1.7跟1.8 中都没有任何同步操作，容易出现并发问题，甚至出现死循环导致系统不可用。解决方案是jdk的ConcurrentHashMap，位于java.util.concurrent下，专门解决并发问题。
###并行跟并发有什么区别？
并发：指应用交替执行不同的任务，多线程原理      
并行：指应用同时执行不用的任务      
区别：一个是交替执行，一个是同时执行。     

###我们为什么要使用线程池？核心线程池内部实现了解吗？
减少创建和销毁线程的次数，每个工作线程都可以被重复利用，可执行多个任务。        
可以根据系统的承受能力，调整线程池中工作线程的数目，放置因为消耗过多的内存，而把服务器累趴下（每个线程大约需要 1 MB 内存，线程开的越多，消耗的内存也就越大，最后死机）      
对于核心的几个线程池，无论是 newFixedThreadPool() 方法，newSingleThreadExecutor() 还是 newCachedThreadPool() 方法，虽然看起来创建的线程有着完全不同的功能特点，但其实内部实现均使用了 ThreadPoolExecutor 实现，其实都只是 ThreadPoolExecutor 类的封装。

###四种线程池的创建
（1）newCachedThreadPool 创建一个可缓存线程池      
（2）newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数。        
（3）newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。        
（4）newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执 行任务      

###线程池队列已满，会发生什么
（1）如果使用的是无界队列 LinkedBlockingQueue，也就是无界队列的话，没关系，继续添 加任务到阻塞队列中等待执行，因为 LinkedBlockingQueue 可以近乎认为是一个无穷大的队 列，可以无限存放任务      
（ 2 ） 如 果 使 用 的 是 有 界 队 列 比 如 ArrayBlockingQueue ， 任 务 首 先 会 被 添 加 到 ArrayBlockingQueue 中，ArrayBlockingQueue 满了，
会根据 maximumPoolSize 的值增加线程 数量，如果增加了线程数量还是处理不过来，ArrayBlockingQueue 继续满，那么则会使用拒 绝策略 RejectedExecutionHandler 处理满了的任务，默认是 AbortPolicy

#Mysql

###Mysql的索引是基于什么？
a. InnoDB：
1. ⽀持事务处理
2. ⽀持外键
3. ⽀持⾏锁
4. 不⽀持FULLTEXT类型的索引（在Mysql5.6已引⼊）
5. 不保存表的具体⾏数，扫描表来计算有多少⾏
6. 对于AUTO_INCREMENT类型的字段，必须包含只有该字段的索
   引
7. DELETE 表时，是⼀⾏⼀⾏的删除
8. InnoDB 把数据和索引存放在表空间⾥⾯
9. 跨平台可直接拷⻉使⽤
10. 表格很难被压缩
    b. MyISAM：
1. 不⽀持事务，回滚将造成不完全回滚，不具有原⼦性
2. 不⽀持外键
3. ⽀持全⽂搜索
4. 保存表的具体⾏数,不带where时，直接返回保存的⾏数
5. DELETE 表时，先drop表，然后重建表
6. MyISAM 表被存放在三个⽂件 。frm ⽂件存放表格定义。 数据
   ⽂件是MYD (MYData) 。 索引⽂件是MYI (MYIndex)引伸
7. 跨平台很难直接拷⻉
8. AUTO_INCREMENT类型字段可以和其他字段⼀起建⽴联合索引
9. 表格可以被压缩
   c. 选择：因为MyISAM相对简单所以在效率上要优于InnoDB.如果系统
   读多，写少。对原⼦性要求低。那么MyISAM最好的选择。且MyISAM
   恢复速度快。可直接⽤备份覆盖恢复。如果系统读少，写多的时候，尤
   其是并发写⼊⾼的时候。InnoDB就是⾸选了。两种类型都有⾃⼰优缺
   点，选择那个完全要看⾃⼰的实际类弄。
   d. InnoDB引擎表是基于B+树的索引组织表
###b+树？
B-tree 利⽤了磁盘块的特性进⾏构建的树。每个磁盘块⼀个节点，      
每个节点包含了很关键字。把树的节点关键字增多后树的层级⽐原来的     
⼆叉树少了，减少数据查找的次数和复杂度。          
B-tree巧妙利⽤了磁盘预读原理，将⼀个节点的⼤⼩设为等于⼀个    
⻚（每⻚为4K），这样每个节点只需要⼀次I/O就可以完全载⼊。     
B-tree 的数据可以存在任何节点中。    

B+tree 是 B-tree 的变种，B+tree 数据只存储在叶⼦节点中。这样在B     
树的基础上每个节点存储的关键字数更多，树的层级更少所以查询数据更快，所    
有指关键字指针都存在叶⼦节点，所以每次查找的次数都相同所以查询速度更稳          
定;    

###mysql数据库中,什么情况下设置了索引但无法使用
a)如果条件中有OR，即使其中有部分条件带索引也不会使用。注意：要想使用or，又想让索引生效，只能将or条件中的每个列都加上索引。   
b)对于多了索引，不是使用的第一部分，则不会使用索引。         
c)Like查询以%开头，不使用索引      
d)存在索引列的数据类型隐形转换，则用不上索引，比如列类型是字符串，那一定要在条件中将数据使用引号引用起来,否则不使用索引       
e)Where 子句里对索引列上有数学运算，用不上索引     
f)Where 子句中对索引列使用函数，用不上索引       
g)Mysql估计使用全表扫描要比用索引快，不使用索引

###什么情况下不推荐使用索引
a)数据唯一性差的字段不要使用索引   
b)频繁更新的字段不要使用索引
c)字段不在where语句中出现时不要添加索引，如果where后含IS NULL/IS NOT NULL/LIKE ‘%输入符%’等条件，不要使用索引     
d)Where子句里对索引使用不等于（<>），不建议使用索引，效果一般

###mysql优化会不会,mycat分库,垂直分库,水平分库?
(1)为查询缓存优化你的查询  
(2)EXPLAIN select查询：explain 的查询结果会告诉你索引主键是如何被利用的        
(3)只需要一行数据时使用limit1     
(4)为搜索字段添加索引        
(5)在关联表的时候使用相当类型的例，并将其索引        
(6)千万不要ORDER BY RAND()      
(7)避免select*        
(8)永远为每张表设置一个ID     
(9)使用ENUM而不是VARCHAR     
(10)从PROCEDURE ANALYS()提取建议     
(11)尽可能的使用NOT NULL      
(12)Java中使用Prepared Statements      
(13)无缓冲的查询      
(14)把IP地址存成UNSIGNED INT     
(15)固定表的长度      
(16)垂直分库：“垂直分割”是一种把数据库中的表按列变成几张表的方法，这样可以降低表的复杂度和字段的数目，从而达到优化的目的。        
(17)水平分库：“水平分割”是一种把数据库中的表按行变成几张表的方法，这样可以降低表的复杂度和字段的数目，从而达到优化的目的。        
(18)越小的列会越快     
(19)选择正确的存储引擎       
(20)使用一个对象关系映射器     
(21)小心永久链接          
(22)拆分大的DELETE活INSERT语句


###如何保证服务幂等性？
1、概念：接⼝的幂等性实际上就是接⼝可重复调⽤，在调⽤⽅多次调⽤的情况下，接⼝最终得到的结果是⼀致的。有些接⼝可以天
然的实现幂等性，⽐如查询接⼝，对于查询来说，你查询⼀次和两次，对于系统来说，没有任何影响，查出的结果也是⼀样。
2、GET幂等：值得注意，幂等性指的是作⽤于结果⽽⾮资源本身。怎么理解呢？例如，这个HTTP GET⽅法可能会每次得到不同的返
回内容，但并不影响资源。
3、POST⾮幂等：因为它会对资源本身产⽣影响，每次调⽤都会有新的资源产⽣，因此不满⾜幂等性。
4、如何保证幂等性：
1、全局唯⼀id：如果使⽤全局唯⼀ID，就是根据业务的操作和内容⽣成⼀个全局ID，在执⾏操作前先根据这个全局唯⼀ID是否存
在，来判断这个操作是否已经执⾏。如果不存在则把全局ID，存储到存储系统中，⽐如数据库、redis等。如果存在则表示该⽅法已经
执⾏。
从⼯程的⻆度来说，使⽤全局ID做幂等可以作为⼀个业务的基础的微服务存在，在很多的微服务中都会⽤到这样的服务，在
每个微服务中都完成这样的功能，会存在⼯作量重复。另外打造⼀个⾼可靠的幂等服务还需要考虑很多问题，⽐如⼀台机器虽然把全
局ID先写⼊了存储，但是在写⼊之后挂了，这就需要引⼊全局ID的超时机制。
使⽤全局唯⼀ID是⼀个通⽤⽅案，可以⽀持插⼊、更新、删除业务操作。但是这个⽅案看起来很美但是实现起来⽐较麻烦，
下⾯的⽅案适⽤于特定的场景，但是实现起来⽐较简单。
2、去重表：这种⽅法适⽤于在业务中有唯⼀标的插⼊场景中，⽐如在以上的⽀付场景中，如果⼀个订单只会⽀付⼀次，所以订
单ID可以作为唯⼀标识。这时，我们就可以建⼀张去重表，并且把唯⼀标识作为唯⼀索引，在我们实现时，把创建⽀付单据和写⼊去
去重表，放在⼀个事务中，如果重复创建，数据库会抛出唯⼀约束异常，操作就会回滚。
3、插⼊或更新：这种⽅法插⼊并且有唯⼀索引的情况，⽐如我们要关联商品品类，其中商品的ID和品类的ID可以构成唯⼀索
引，并且在数据表中也增加了唯⼀索引。这时就可以使⽤InsertOrUpdate操作。
4、多版本控制：这种⽅法适合在更新的场景中，⽐如我们要更新商品的名字，这时我们就可以在更新的接⼝中增加⼀个版本
号，来做幂等
5、状态机控制：这种⽅法适合在有状态机流转的情况下，⽐如就会订单的创建和付款，订单的付款肯定是在之前，这时我们可
以通过在设计状态字段时，使⽤int类型，并且通过值类型的⼤⼩来做幂等

###说一下数据库的事务隔离？
MySQL 的事务隔离是在 MySQL. ini 配置文件里添加的，在文件的最后添加：     
transaction-isolation = REPEATABLE-READ     
可用的配置值：READ-UNCOMMITTED、READ-COMMITTED、REPEATABLE-READ、SERIALIZABLE。        
READ-UNCOMMITTED：未提交读，最低隔离级别、事务未提交前，就可被其他事务读取（会出现幻读、脏读、不可重复读）。     
READ-COMMITTED：提交读，一个事务提交后才能被其他事务读取到（会造成幻读、不可重复读）。     
REPEATABLE-READ：可重复读，默认级别，保证多次读取同一个数据时，其值都和事务开始时候的内容是一致，禁止读取到别的事务未提交的数据（会造成幻读）。        
SERIALIZABLE：序列化，代价最高最可靠的隔离级别，该隔离级别能防止脏读、不可重复读、幻读。     
脏读 ：表示一个事务能够读取另一个事务中还未提交的数据。比如，某个事务尝试插入记录 A，此时该事务还未提交，然后另一个事务尝试读取到了记录 A。        
不可重复读 ：是指在一个事务内，多次读同一数据。        
幻读 ：指同一个事务内多次查询返回的结果集不一样。比如同一个事务 A 第一次查询时候有 n 条记录，但是第二次同等条件下查询却有 n+1 条记录，这就好像产生了幻觉。发生幻读的原因也是另外一个事务新增或者删除或者修改了第一个事务结果集里面的数据，同一个记录的数据内容被修改了，所有数据行的记录就变多或者变少了。

###mysql的存储引擎了解过没有?
![img_1.png](../面试Img/img_1.png)       
MyISAM	高速引擎，拥有较高的插入，查询速度，但不支持事务    
InnoDB	5.5版本后MySQL的默认数据库，支持事务和行级锁定，比MyISAM处理速度稍慢     
ISAM	MyISAM的前身，MySQL5.0以后不再默认安装     
MRG_MyISAM（MERGE）	将多个表联合成一个表使用，在超大规模数据存储时很有用     
Memory	内存存储引擎，拥有极高的插入，更新和查询效率。但是会占用和数据量成正比的内存空间。只在内存上保存数据，意味着数据可能会丢失      
Falcon	一种新的存储引擎，支持事物处理，传言可能是InnoDB的替代者      
Archive	将数据压缩后进行存储，非常适合存储大量的独立的，作为历史记录的数据，但是只能进行插入和查询操作     
CSV	CSV 存储引擎是基于 CSV 格式文件存储数据(应用于跨平台的数据交换)    


事务处理：在整个流程中出现任何问题，都能让数据回滚到最开始的状态，这种处理方式称之为事务处理。也就是说事务处理要么都成功，要么的失败。

###mysql调优
1、选择最合适的字段属性：类型、⻓度、是否允许NULL等；尽量把字段设为not null，⼀⾯查询时对⽐是否为null；   
2.要尽量避免全表扫描，⾸先应考虑在 where 及 order by 涉及的列上建⽴索引。  
3.应尽量避免在 where ⼦句中对字段进⾏ null 值判断、使⽤!= 或 <> 操作符，否则将导致引擎放弃使⽤索引⽽进⾏全表扫描     
4.应尽量避免在 where ⼦句中使⽤ or 来连接条件，如果⼀个字段有索引，⼀个字段没有索引，将导致引擎放弃使⽤索引⽽进⾏全表扫描     
5.in 和 not in 也要慎⽤，否则会导致全表扫描     
6.模糊查询也将导致全表扫描，若要提⾼效率，可以考虑字段建⽴前置索引或⽤全⽂检索；    
7.如果在 where ⼦句中使⽤参数，也会导致全表扫描。因为SQL只有在运⾏时才会解析局部变量，但优化程序不能将访问计划的选择推迟到运    
⾏时；它必须在编译时进⾏选择。然 ⽽，如果在编译时建⽴访问计划，变量的值还是未知的，因⽽⽆法作为索引选择的输⼊项。      
9.应尽量避免在where⼦句中对字段进⾏函数操作，这将导致引擎放弃使⽤索引⽽进⾏全表扫描。     
10.不要在 where ⼦句中的“=”左边进⾏函数、算术运算或其他表达式运算，否则系统将可能⽆法正确使⽤索引。    
11.在使⽤索引字段作为条件时，如果该索引是复合索引，那么必须使⽤到该索引中的第⼀个字段作为条件时才能保证系统使⽤该索引，否则该     
索引将不会被使⽤，并且应尽可能的让字段顺序与索引顺序相⼀致。      
12.不要写⼀些没有意义的查询，如需要⽣成⼀个空表结构：     
13.Update 语句，如果只更改1、2个字段，不要Update全部字段，否则频繁调⽤会引起明显的性能消耗，同时带来⼤量⽇志。     
14.对于多张⼤数据量（这⾥⼏百条就算⼤了）的表JOIN，要先分⻚再JOIN，否则逻辑读会很⾼，性能很差。    
15.select count(*) from table；这样不带任何条件的count会引起全表扫描，并且没有任何业务意义，是⼀定要杜绝的。    
16.索引并不是越多越好，索引固然可以提⾼相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或      
update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况⽽定。⼀个表的索引数最好不要超过6个，若太多则应考虑⼀些不常使⽤到      
的列上建的索引是否有 必要。    
17.应尽可能的避免更新 clustered 索引数据列，因为 clustered 索引数据列的顺序就是表记录的物理存储顺序，⼀旦该列值改变将导致     
整个表记录的顺序的调整，会耗费相当⼤的资源。若应⽤系统需要频繁更新 clustered 索引数据列，那么需要考虑是否应将该索引建为    
clustered 索引。     
18.尽量使⽤数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。这是因为引擎在处     
理查询和连 接时会逐个⽐较字符串中每⼀个字符，⽽对于数字型⽽⾔只需要⽐较⼀次就够了。      
19.尽可能的使⽤ varchar/nvarchar 代替 char/nchar ，因为⾸先变⻓字段存储空间⼩，可以节省存储空间，其次对于查询来说，在⼀     
个相对较⼩的字段内搜索效率显然要⾼些。     
20.任何地⽅都不要使⽤ select * from t ，⽤具体的字段列表代替“*”，不要返回⽤不到的任何字段。      
21.尽量使⽤表变量来代替临时表。如果表变量包含⼤量数据，请注意索引⾮常有限（只有主键索引）。    
22. 避免频繁创建和删除临时表，以减少系统表资源的消耗。临时表并不是不可使⽤，适当地使⽤它们可以使某些例程更有效，例如，当需要重
复引⽤⼤型表或常⽤表中的某个数据集时。但是，对于⼀次性事件， 最好使⽤导出表。
23. 在新建临时表时，如果⼀次性插⼊数据量很⼤，那么可以使⽤ select into 代替 create table，避免造成⼤量 log ，以提⾼速度；
如果数据量不⼤，为了缓和系统表的资源，应先create table，然后insert。 
24. 如果使⽤到了临时表，在存储过程的最后务必将所有的临时表显式删除，先 truncate table ，然后 drop table ，这样可以避免系统
表的较⻓时间锁定。
25. 尽量避免使⽤游标，因为游标的效率较差，如果游标操作的数据超过1万⾏，那么就应该考虑改写。
26. 使⽤基于游标的⽅法或临时表⽅法之前，应先寻找基于集的解决⽅案来解决问题，基于集的⽅法通常更有效。
27. 与临时表⼀样，游标并不是不可使⽤。对⼩型数据集使⽤ FAST_FORWARD 游标通常要优于其他逐⾏处理⽅法，尤其是在必须引⽤⼏个表才
能获得所需的数据时。在结果集中包括“合计”的例程通常要⽐使⽤游标执⾏的速度快。如果开发时 间允许，基于游标的⽅法和基于集的⽅法都可以尝
试⼀下，看哪⼀种⽅法的效果更好。
28. 在所有的存储过程和触发器的开始处设置 SET NOCOUNT ON ，在结束时设置 SET NOCOUNT OFF 。⽆需在执⾏存储过程和触发器的每个
语句后向客户端发送 DONE_IN_PROC 消息。
29. 尽量避免⼤事务操作，提⾼系统并发能⼒。
30. 尽量避免向客户端返回⼤数据量，若数据量过⼤，应该考虑相应需求是否合理。

#分布式



#JVM

###什么是双亲委派模型？
等于是说加载 Class **文件的原理机制**    
Java 中的所有类，都需要由类加载器装载到 JVM 中才能运行。   
在介绍双亲委派模型之前先说下类加载器。对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立在 JVM 中的唯一性，每一个类加载器，都有一个独立的类名称空间。类加载器就是根据指定全限定名称将 class 文件加载到 JVM 内存，然后再转化为 class 对象。      
类加载器分类：             
启动类加载器（Bootstrap ClassLoader），是虚拟机自身的一部分，用来加载Java_HOME/lib/目录中的，或者被 -Xbootclasspath 参数所指定的路径中并且被虚拟机识别的类库；      
其他类加载器         
扩展类加载器（Extension ClassLoader）：负责加载<Java_HOME>\lib\ext目录或Java. ext. dirs系统变量指定的路径中的所有类库；        
应用程序类加载器（Application ClassLoader）。负责加载用户类路径（classpath）上的指定类库，我们可以直接使用这个类加载器。一般情况，如果我们没有自定义类加载器默认就是用这个加载器。      
双亲委派模型：如果一个类加载器收到了类加载的请求，它首先不会自己去加载这个类，而是把这个请求委派给父类加载器去完成，每一层的类加载器都是如此，这样所有的加载请求都会被传送到顶层的启动类加载器中，只有当父加载无法完成加载请求（它的搜索范围中没找到所需的类）时，子加载器才会尝试去加载类。

###堆结构
堆内存是由存活和死亡的对象组成的。存活的对象是应用可以访问的，不会被垃圾回收。      
死 亡的对象是应用不可访问尚且还没有被垃圾收集器回收掉的对象。一直到垃圾收集器把这些 对象回收掉之前，他们会一直占据堆内存空间。     
###虚拟机中的共划分为三个代
年轻代（Young Generation）、年老代（Old Generation）和持久代（Permanent Generation）
年轻代: 所有新生成的对象首先都是放在年轻代的。年轻代的目标就是尽可能快速的收集掉那些生 命周期短的对象。年轻代分三个区。一个 Eden 区，两个 Survivor 区(一般而言)。大部分对 象在 Eden 区中生成。当 Eden 区满时，还存活的对象将被复制到 Survivor 区（两个中的一个）， 当这个 Survivor 区满时，此区的存活对象将被复制到另外一个 Survivor 区，当这个 Survivor 去也满了的时候，从第一个 Survivor 区复制过来的并且此时还存活的对象，将被复制“年老 区(Tenured)”。需要注意，Survivor 的两个区是对称的，没先后关系，所以同一个区中可能同 时存在从 Eden 复制过来对象，和从前一个 Survivor 复制过来的对象，而复制到年老区的只 有从第一个 Survivor 去过来的对象。而且，Survivor 区总有一个是空的。同时，根据程序需 要，Survivor 区是可以配置为多个的（多于两个），这样可以增加对象在年轻代中的存在时 间，减少被放到年老代的可能。 年老代: 在年轻代中经历了 N 次垃圾回收后仍然存活的对象，就会被放到年老代中。因此，可以认 为年老代中存放的都是一些生命周期较长的对象。 持久代: 用于存放静态文件，如今 Java 类、方法等。持久代对垃圾回收没有显著影响，但是有些应 用可能动态生成或者调用一些 class，例如 Hibernate 等，在这种时候需要设置一个比较大的 持久代空间来存放这些运行过程中新增的类。持久代大小通过-XX:MaxPermSize=进行设置。

###类加载过程？
装载、链接和 初始化，其中链接又可以分成校验、准备、解析 装载：查找和导入类或接口的二进制数据；   
链接：执行下面的校验、准备和解析步骤，其中解析步骤是可以选择的；    
校验：检查导入类或接口的二进制数据的正确性；  
准备：给类的静态变量分配并初始化存储空间；   
解析：将符号引用转成直接引用；   
初始化：激活类的静态变量,初始化 Java 代码和静态 Java 代码块   


###七个垃圾回收器之间如何搭配使⽤
1. Serial New收集器是针对新⽣代的收集器，采⽤的是复制算法；
2. Parallel New（并⾏）收集器，新⽣代采⽤复制算法，⽼年代采⽤标记整理；
3. Parallel Scavenge（并⾏）收集器，针对新⽣代，采⽤复制收集算法；
4. Serial Old（串⾏）收集器，新⽣代采⽤复制，⽼年代采⽤标记清理；
5. Parallel Old（并⾏）收集器，针对⽼年代，标记整理；
6. CMS收集器，基于标记清理；
7. G1收集器(JDK)：整体上是基于标记清理，局部采⽤复制；
   综上：新⽣代基本采⽤复制算法，⽼年代采⽤标记整理算法。cms采⽤标记清理；

###JVM 由哪些部分组成？
解析：这是对 JVM 体系结构的考察  
答：JVM 的结构基本上由 4 部分组成：   
**类加载器**，在 JVM 启动时或者类运行时将需要的 class 加载到 JVM 中    
**执行引擎**，执行引擎的任务是负责执行 class 文件中包含的字节码指令，相当于实际机器上的 CPU   
**内存区**，将内存划分成若干个区以模拟实际机器上的存储、记录和调度功能模块，如实际机器上的各种功能的寄存器或者 PC 指针的记录器等    
**本地方法调用**，调用 C 或 C++ 实现的本地方法的代码返回结果

###说一下 JVM 调优的工具？
JDK 自带了很多监控工具，都位于 JDK 的 bin 目录下，其中最常用的是 jconsole 和 jvisualvm 这两款视图监控工具。  
jconsole：用于对 JVM 中的内存、线程和类等进行监控；   
jvisualvm：JDK 自带的全能分析工具，可以分析：内存快照、线程快照、程序死锁、监控内存的变化、gc 变化等。

###常用的 JVM 调优的参数都有哪些？
-Xms2g：初始化推大小为 2g；     
-Xmx2g：堆最大内存为 2g；      
-XX:NewRatio=4：设置年轻的和老年代的内存比例为 1:4；        
-XX:SurvivorRatio=8：设置新生代 Eden 和 Survivor 比例为 8:2；     
–XX:+UseParNewGC：指定使用 ParNew + Serial Old 垃圾回收器组合；     
-XX:+UseParallelOldGC：指定使用 ParNew + ParNew Old 垃圾回收器组合；        
-XX:+UseConcMarkSweepGC：指定使用 CMS + Serial Old 垃圾回收器组合；     
-XX:+PrintGC：开启打印 gc 信息；   
-XX:+PrintGCDetails：打印 gc 详细信息。

###类加载器是有了解吗？
解析：底层原理的考察，其中涉及到类加载器的概念，功能以及一些底层的实现。        
答：顾名思义，类加载器（class loader）用来加载 Java 类到 Java 虚拟机中。一般来说，Java 虚拟机使用 Java 类的方式如下：Java 源程序（.java 文件）在经过 Java 编译器编译之后就被转换成 Java 字节代码（.class 文件）。       
类加载器负责读取 Java 字节代码，并转换成 java.lang.Class类的一个实例。每个这样的实例用来表示一个 Java 类。通过此实例的 newInstance()方法就可以创建出该类的一个对象。

###有没有jvm调优经验？调优⽅案有哪些？
1. 调优时机：
   a. heap 内存（⽼年代）持续上涨达到设置的最⼤内存值；
   b. Full GC 次数频繁；
   c. GC 停顿时间过⻓（超过1秒）；
   d. 应⽤出现OutOfMemory 等内存异常；
   e. 应⽤中有使⽤本地缓存且占⽤⼤量内存空间；
   f. 系统吞吐量与响应性能不⾼或下降。
2. 调优原则：
   a. 多数的Java应⽤不需要在服务器上进⾏JVM优化；
   b. 多数导致GC问题的Java应⽤，都不是因为我们参数设置错误，
   ⽽是代码问题；
   c. 在应⽤上线之前，先考虑将机器的JVM参数设置到最优（最适
   合）；
   d. 减少创建对象的数量；
   e. 减少使⽤全局变量和⼤对象；
   f. JVM优化是到最后不得已才采⽤的⼿段；
   g. 在实际使⽤中，分析GC情况优化代码⽐优化JVM参数更好；
3. 调优⽬标：
   a. GC低停顿；
   b. GC低频率；
   c. 低内存占⽤；
   d. ⾼吞吐量；
4. 调优步骤：
   a. 分析GC⽇志及dump⽂件，判断是否需要优化，确定瓶颈问题
   点；
   b. 确定jvm调优量化⽬标；
   c. 确定jvm调优参数（根据历史jvm参数来调整）；
   d. 调优⼀台服务器，对⽐观察调优前后的差异；
   e. 不断的分析和调整，知道找到合适的jvm参数配置；
   f. 找到最合适的参数，将这些参数应⽤到所有服务器，并进⾏后续跟踪。


#有没了解Docker，Docker和虚拟机有什么区别？
1、虚拟机：我们传统的虚拟机需要模拟整台机器包括硬件，每台虚拟机都需要有⾃⼰的操作系统，虚拟机⼀旦被开启，预分配
给他的资源将全部被占⽤。，每⼀个虚拟机包括应⽤，必要的⼆进制和库，以及⼀个完整的⽤户操作系统。
2、Docker：容器技术是和我们的宿主机共享硬件资源及操作系统可以实现资源的动态分配。
容器包含应⽤和其所有的依赖包，但是与其他容器共享内核。容器在宿主机操作系统中，在⽤户空间以分离的进程运⾏。
3、对⽐：
1. docker启动快速属于秒级别。虚拟机通常需要⼏分钟去启动。
2. docker需要的资源更少，docker在操作系统级别进⾏虚拟化，docker容器和内核交互，⼏乎没有性能损耗，性能优于通过
   Hypervisor层与内核层的虚拟化。；
3. docker更轻量，docker的架构可以共⽤⼀个内核与共享应⽤程序库，所占内存极⼩。同样的硬件环境，Docker运⾏的镜
   像数远多于虚拟机数量。对系统的利⽤率⾮常⾼
4. 与虚拟机相⽐，docker隔离性更弱，docker属于进程之间的隔离，虚拟机可实现系统级别隔离；
5. 安全性： docker的安全性也更弱。Docker的租户root和宿主机root等同，⼀旦容器内的⽤户从普通⽤户权限提升为root
   权限，它就直接具备了宿主机的root权限，进⽽可进⾏⽆限制的操作。虚拟机租户root权限和宿主机的root虚拟机权限是分离的，并且
   虚拟机利⽤如Intel的VT-d和VT-x的ring-1硬件隔离技术，这种隔离技术可以防⽌虚拟机突破和彼此交互，⽽容器⾄今还没有任何形式
   的硬件隔离，这使得容器容易受到攻击。
6. 可管理性：docker的集中化管理⼯具还不算成熟。各种虚拟化技术都有成熟的管理⼯具，例如VMware vCenter提供完备
   的虚拟机管理能⼒。
7. ⾼可⽤和可恢复性：docker对业务的⾼可⽤⽀持是通过快速重新部署实现的。虚拟化具备负载均衡，⾼可⽤，容错，迁移
   和数据保护等经过⽣产实践检验的成熟保障机制，VMware可承诺虚拟机99.999%⾼可⽤，保证业务连续性。
8. 快速创建、删除：虚拟化创建是分钟级别的，Docker容器创建是秒级别的，Docker的快速迭代性，决定了⽆论是开发、测
   试、部署都可以节约⼤量时间。
9. 交付、部署：虚拟机可以通过镜像实现环境交付的⼀致性，但镜像分发⽆法体系化；Docker在Dockerfile中记录了容器构
   建过程，可在集群中实现快速分发和快速部署;
5. 同⼀个宿主机中多个Docker容器之间如何通信？多个宿主机中Docker容器之间如何通信？
   1、这⾥同主机不同容器之间通信主要使⽤Docker桥接（Bridge）模式。
   2、不同主机的容器之间的通信可以借助于 pipework 这个⼯具。

###如何保证单机保证3wtps访问量？
答：今天面试被问道一个问题，如何保证单机保证3wtps的访问量？    
听到这个问题，第一反应有点蒙，想成了3w的并发量了，想了一下，目前的容器比如tomcat的最大并发量也就几千就扛不住了...      
后来我先说IO模型使用NOI,能够处理小数据大并发的请求，然后从代码优化上说要尽量并行处理逻辑，以及优化JVM，调整堆大小，减少FullGC，使停顿时间减少，最终使每个请求的处理时间减少。      
但是也知道这个说法挺不搭题的....      
后来面试官跟我说从两方面来分析，一方面是从请求上来说，将多个请求合并成一个请求发送，减少请求次数，一方面是把请求都改成异步的，后台处理，让请求过来之后就直接返回成功。     
当时感觉这两个方面说的也没问题。毕竟第一次出去面试，脑袋瓜子里有些蒙了，然后后边就是随便聊了一下我个人擅长的方面，我就说了一下自己项目上使用的springCloud,的一些核心组件及注册中心的实现原理等，然后就没有然后了...       
感觉这次面试基本是凉了，但是也还好，做好了准备，第一次面试当做总结经验教训了吧。        
回来的路上，也一直在思考这个问题，有了一些想法：
1. 首先从题目的说明上，本身存在一些问题，说的是要保证3W的tps，但是如果将请求合并了，是减少了请求次数，但是也打不到3w的tps了啊，这样本身就不符合这个题目的要求了，所以我认为要么修改题目的说明，要么这个3w tps就是一个固定值，无法通过外部优化来减少了，只能从系统内部去优化。
2. 然后从系统优化来说，这个题目本身也存在一定的问题，就是这3w的tps到底是峰值流量还是平时流量，是需要同步给出处理结果，还是可以接受异步的后续返回处理结果。
   如果是需要同步给出处理结果，那么就只能从业务处理流程上进行优化，也就是尽量把串行的处理流程改成并行的处理流程，把查询尽量从数据库改到缓存中。但是即使这样，一个需要同步返回结果的3w tps单机处理，每个请求的处理时间=1%3000≈0.00033秒=0.33微妙，感觉在时间上是根本无法处理完一个业务流程的。如果一个业务流程无法处理完的话，那么请求就会出现堆积现象，堆积过多就会出现OOM，内存溢出了...所以我个人感觉这个单机3W同步处理的优化是不符合现实的，只能从业务上去处理，尽量把同步的业务逻辑改成异步的业务逻辑，即使改成异步的业务逻辑，虽然能够支撑住3w的tps，但是因为服务的处理速刷无法达到3wtps的处理速度，那么最终会造成内存的不断消耗，最终导致OOM的出现。
3. 看这个tps到底是峰值还是平时了，如果只是峰值3w，平时很低，而且可以使用异步的话，那么就可以使用MQ了，请求过来直接把请求发送到MQ中去，不处理业务。然后创建消费者去消费这些消息。达到削峰填谷目的。
4. 计算一下，如果一个请求的处理时间是10ms，那么单线程每秒的处理速度=1000%10=100个，采用并行处理，如果是一个四核八线程的处理器，理论上创建16个线程去处理，那么每秒的处理速度=100*16=1600个。不知道这样的计算方法是否正确.

###GC的四种清理算法
1.标记-清除  
2.复制算法      所有对象都复制一遍，并将所有引用地址重置一遍,还浪费一半内存
3.标记-整理压缩              
4.分代收集   
5.引用计数法  一个引用计数器，每当一个地方引用这个对象时，计数器值+1；当引用失效时，计数器值-1。基本没有在对象之间引用
6.可达性分析法 虚拟机会将一些对象定义为 GC Roots，从 GC Roots 沿着引用链 向下寻找，如果某个对象不能通过 GC Roots 寻找到，虚拟机就认为该对象可以被回收掉

###哪些对象可以被看做是 GC Roots 呢？     
1）虚拟机栈（栈帧中的本地变量表）中引用的对象；      
2）方法区中的类静态属性引用的对象，常量引用的对象；       
3）本地方法栈中 JNI(Native 方法）引用的对象；       


###对象不可达，一定会被垃圾收集器回收么？ 
即使不可达，对象也不一定会被垃圾收集器回收，     
1）先判断对象是否有必要执行 finalize() 方法，对象必须重写 finalize()方法且没有被运行过。    
2）若有必要执行，会把对象放到一个 队列中，JVM 会开一个线程去回收它们，这是对象最后一次可以逃逸清理的机会。    

###对象的四种引用
强引用 只要引用存在，垃圾回收器永远不会回收     
```java
Object obj = new Object(); 
User user=new User();
```
软引用 非必须引用，内存溢出之前进行回收    
```java
Object obj = new Object(); 
SoftReference<Object> sf = new SoftReference<Object>(obj);
obj = null; sf.get();//有时候会返回null

```
弱引用 第二次垃圾回收时回收    
```java
Object obj = new Object(); 
WeakReference<Object> wf = new WeakReference<Object>(obj);
obj = null; wf.get();
//有时候会返回null wf.isEnQueued();//返回是否被垃圾回收器标记为即将回收的垃圾

```
虚引用 垃圾回收时回收，无法通过引用取到对象值
```java
Object obj = new Object(); 
PhantomReference<Object> pf = new PhantomReference<Object>(obj); 
obj=null; pf.get();//永远返回null pf.isEnQueued();//返回是否从内存中已经删除

```
###静态代理和动态代理的区别，什么场景使用？
1）静态代理：由程序员创建或是由特定工具生成，在代码编译时就确定了被代理的类是哪 一个是静态代理。静态代理通常只代理一个类；       
2）动态代理：在代码运行期间，运用反射机制动态创建生成。动态代理代理的是一个接口 下的多个实现类；     

实现步骤：
a.实现 InvocationHandler 接口创建自己的调用处理器；   
b.给 Proxy 类提供 ClassLoader 和代理接口类型数组创建动态代理类；  
c.利用反射机制得到动态代理类的构造函 数；  
d.利用动态代理类的构造函数创建动态代理类对象；   
使用场景：Retrofit 中直接调用接口的方法；Spring 的 AOP 机制；



#kafka
###Kafka的设计时什么样的呢？
Kafka将消息以topic为单位进行归纳       
将向Kafka topic发布消息的程序成为producers.        
将预订topics并消费消息的程序成为consumer.        
Kafka以集群的方式运行，可以由一个或多个服务组成，每个服务叫做一个broker.      
producers通过网络将消息发送到Kafka集群，集群向消费者提供消息

###kafka 的 message 包括哪些信息
Message 由一个固定长度的 header 和一个变长的消息体 body 组成       
header 部分由一个字节的 magic(文件格式)和四个字节的 CRC32(用于判断 body 消息体 是否正常)构成。    
当magic 的值为 1 的时候，会在 magic 和 crc32 之间多一个字节的数据：      
attributes(保存一些相关属性，比如是否压缩、压缩格式等等)；    
如果 magic 的值为 0，那 么不存在 attributes 属性 body 是由 N 个字节构成的一个消息体，包含了具体的 key/value 消息    

###kafka 的数据存在内存还是磁盘
磁盘,经过测试磁盘的顺序读写速度和内存持平
###数据传输的事物定义有哪三种？
数据传输的事务定义通常有以下三种级别：         
（1）最多一次: 消息不会被重复发送，最多被传输一次，但也有可能一次不传输       
（2）最少一次: 消息不会被漏发送，最少被传输一次，但也有可能被重复传输.       
（3）精确的一次（Exactly once）: 不会漏传输也不会重复传输,每个消息都传输被一次而且仅仅被传输一次，这是大家所期望的

###Kafka判断一个节点是否还活着有那两个条件？
（1）节点必须可以维护和ZooKeeper的连接，Zookeeper通过心跳机制检查每个节点的连接       
（2）如果节点是个follower,他必须能及时的同步leader的写操作，延时不能太久

###producer是否直接将数据发送到broker的leader(主节点)？
producer直接将数据发送到broker的leader(主节点)，不需要在多个节点进行分发，为了帮助producer做到这点，所有的Kafka节点都可以及时的告知:哪些节点是活动的，目标topic目标分区的leader在哪。这样producer就可以直接将消息发送到目的地了

###Kafa consumer是否可以消费指定分区消息？
Kafa consumer消费消息时，向broker发出"fetch"请求去消费特定分区的消息，consumer指定消息在日志中的偏移量（offset），就可以消费从这个位置开始的消息，customer拥有了offset的控制权，可以向后回滚去重新消费之前的消息，这是很有意义的

###Kafka消息是采用Pull模式，还是Push模式？
Kafka最初考虑的问题是，customer应该从brokes拉取消息还是brokers将消息推送到consumer，也就是pull还push。在这方面，Kafka遵循了一种大部分消息系统共同的传统的设计：producer将消息推送到broker，consumer从broker拉取消息     
一些消息系统比如Scribe和Apache Flume采用了push模式，将消息推送到下游的consumer。这样做有好处也有坏处：由broker决定消息推送的速率，对于不同消费速率的consumer就不太好处理了。消息系统都致力于让consumer以最大的速率最快速的消费消息，但不幸的是，push模式下，当broker推送的速率远大于consumer消费的速率时，consumer恐怕就要崩溃了。最终Kafka还是选取了传统的pull模式       
Pull模式的另外一个好处是consumer可以自主决定是否批量的从broker拉取数据。Push模式必须在不知道下游consumer消费能力和消费策略的情况下决定是立即推送每条消息还是缓存之后批量推送。如果为了避免consumer崩溃而采用较低的推送速率，将可能导致一次只推送较少的消息而造成浪费。Pull模式下，consumer就可以根据自己的消费能力去决定这些策略       
Pull有个缺点是，如果broker没有可供消费的消息，将导致consumer不断在循环中轮询，直到新消息到t达。为了避免这点，Kafka有个参数可以让consumer阻塞知道新消息到达(当然也可以阻塞知道消息的数量达到某个特定的量这样就可以批量发

###Kafka存储在硬盘上的消息格式是什么？
消息由一个固定长度的头部和可变长度的字节数组组成。头部包含了一个版本号和CRC32校验码。       
消息长度: 4 bytes (value: 1+4+n)       
版本号: 1 byte        
CRC校验码: 4 bytes        
具体的消息: n bytes

###Kafka高效文件存储设计特点：
(1).Kafka把topic中一个parition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。        
(2).通过索引信息可以快速定位message和确定response的最大大小。        
(3).通过index元数据全部映射到memory，可以避免segment file的IO磁盘操作。      
(4).通过索引文件稀疏存储，可以大幅降低index文件元数据占用空间大小。

###Kafka 与传统消息系统之间有三个关键区别
(1).Kafka 持久化日志，这些日志可以被重复读取和无限期保留       
(2).Kafka 是一个分布式系统：它以集群的方式运行，可以灵活伸缩，在内部通过复制数据提升容错能力和高可用性        
(3).Kafka 支持实时的流式处理

###Kafka创建Topic时如何将分区放置到不同的Broker中
副本因子不能大于 Broker 的个数；       
第一个分区（编号为0）的第一个副本放置位置是随机从 brokerList 选择的；      
其他分区的第一个副本放置位置相对于第0个分区依次往后移。也就是如果我们有5个 Broker，5个分区，假设第一个分区放在第四个 Broker 上，那么第二个分区将会放在第五个 Broker 上；第三个分区将会放在第一个 Broker 上；第四个分区将会放在第二个 Broker 上，依次类推；     
剩余的副本相对于第一个副本放置位置其实是由 nextReplicaShift 决定的，而这个数也是随机产生的

###Kafka新建的分区会在哪个目录下创建
在启动 Kafka 集群之前，我们需要配置好 log.dirs 参数，其值是 Kafka 数据的存放目录，这个参数可以配置多个目录，目录之间使用逗号分隔，通常这些目录是分布在不同的磁盘上用于提高读写性能。      
当然我们也可以配置 log.dir 参数，含义一样。只需要设置其中一个即可。      
如果 log.dirs 参数只配置了一个目录，那么分配到各个 Broker 上的分区肯定只能在这个目录下创建文件夹用于存放数据。        
但是如果 log.dirs 参数配置了多个目录，那么 Kafka 会在哪个文件夹中创建分区目录呢？答案是：Kafka 会在含有分区目录最少的文件夹中创建新的分区目录，分区目录名为 Topic名+分区ID。注意，是分区文件夹总数最少的目录，而不是磁盘使用量最少的目录！也就是说，如果你给 log.dirs 参数新增了一个新的磁盘，新的分区目录肯定是先在这个新的磁盘上创建直到这个新的磁盘目录拥有的分区目录不是最少为止。

###partition的数据如何保存到硬盘
topic中的多个partition以文件夹的形式保存到broker，每个分区序号从0递增，      
且消息有序       
Partition文件下有多个segment（xxx.index，xxx.log）       
segment 文件里的 大小和配置文件大小一致可以根据要求修改 默认为1g      
如果大小大于1g时，会滚动一个新的segment并且以上一个segment最后一条消息的偏移量命名

###kafka的ack机制
request.required.acks有三个值 0 1 -1        
0:生产者不会等待broker的ack，这个延迟最低但是存储的保证最弱当server挂掉的时候就会丢数据        
1：服务端会等待ack值 leader副本确认接收到消息后发送ack但是如果leader挂掉后他不确保是否复制完成新leader也会导致数据丢失        
-1：同样在1的基础上 服务端会等所有的follower的副本受到数据后才会受到leader发出的ack，这样数据不会丢失

###Kafka的消费者如何消费数据
消费者每次消费数据的时候，消费者都会记录消费的物理偏移量（offset）的位置     
等到下次消费时，他会接着上次位置继续消费

###怎么解决 kafka 的数据丢失
producer 端： 宏观上看保证数据的可靠安全性，肯定是依据分区数做好数据备份，设立副本数。      
broker 端： topic 设置多分区，分区自适应所在机器，为了让各分区均匀分布在所在的 broker 中，分 区数要大于 broker 数。 分区是 kafka 进行并行读写的单位，是提升 kafka 速度的关键。     
Consumer 端 consumer 端丢失消息的情形比较简单：如果在消息处理完成前就提交了 offset，那么就有    
可能造成数据的丢失。由于 Kafka consumer 默认是自动提交位移的，所以在后台提交位 移前一定要保证消息被正常处理了，因此不建议采用很重的处理逻辑，如果处理耗时很长， 则建议把逻辑放到另一个线程中去做。为了避免数据丢失，     
现给出两点建议： enable.auto.commit=false 关闭自动提交位移 在消息被完整处理之后再手动提交位移      

###消费者负载均衡策略
一个消费者组中的一个分片对应一个消费者成员，他能保证每个消费者成员都能访问，如果组中成员太多会有空闲的成员

###数据有序
一个消费者组里它的内部是有序的
消费者组与消费者组之间是无序的

###kafaka生产数据时数据的分组策略
生产者决定数据产生到集群的哪个partition中   
每一条消息都是以（key，value）格式   
Key是由生产者发送数据传入  
所以生产者（key）决定了数据产生到集群的哪个partition


###为什么要对Topic下数据进行分区存储？
1、commit log文件会受到所在机器的文件系统大小的限制，分区之后，理论上一个topic可以处理任意数量的数据。
2、为了提高并行度。


###kafka 可以脱离 zookeeper 单独使用吗？为什么？
kafka 不能脱离 zookeeper 单独使用，因为 kafka 使用 zookeeper 管理和协调 kafka 的节点服务器。
###kafka 有几种数据保留的策略？
kafka 有两种数据保存策略：按照过期时间保留和按照存储的消息大小保留。   
kafka 同时设置了 7 天和 10G 清除数据，到第五天的时候消息达到了 10G，这个时候 kafka 将如何处理？    
这个时候 kafka 会执行数据清除工作，时间和大小不论那个满足条件，都会清空数据。
###什么情况会导致 kafka 运行变慢？
cpu 性能瓶颈    
磁盘读写瓶颈  
网络瓶颈
###使用 kafka 集群需要注意什么？
集群的数量不是越多越好，最好不要超过 7 个，因为节点越多，消息复制需要的时间就越长，整个群组的吞吐量就越低。     
集群数量最好是单数，因为超过一半故障集群就不能用了，设置为单数容错率更高。

###如何获取 topic 主题的列表
bin/kafka-topics.sh --list --zookeeper localhost:2181

###生产者和消费者的命令行是什么？
生产者在主题上发布消息：
bin/kafka-console-producer.sh --broker-list 192.168.43.49:9092 --topic  
Hello-Kafka
注意这里的 IP 是 server.properties 中的 listeners 的配置。接下来每个新行就是
输入一条新消息。    
消费者接受消息：    
bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic    
Hello-Kafka --from-beginning

###consumer 是推还是拉？
Kafka 最初考虑的问题是，customer 应该从 brokes 拉取消息还是 brokers 将消    
息推送到 consumer，也就是 pull 还 push。在这方面，Kafka 遵循了一种大部分   
消息系统共同的传统的设计：producer 将消息推送到 broker，consumer 从  
broker 拉取消息。    
一些消息系统比如 Scribe 和 Apache Flume 采用了 push 模式，将消息推送到下  
游的 consumer。这样做有好处也有坏处：由 broker 决定消息推送的速率，对于    
不同消费速率的 consumer 就不太好处理了。消息系统都致力于让 consumer 以   
最大的速率最快速的消费消息，但不幸的是，push 模式下，当 broker 推送的速  
率远大于 consumer 消费的速率时，consumer 恐怕就要崩溃了。最终 Kafka 还    
是选取了传统的 pull 模式。    
Pull 模式的另外一个好处是 consumer 可以自主决定是否批量的从 broker 拉取数    
据。Push 模式必须在不知道下游 consumer 消费能力和消费策略的情况下决定是
立即推送每条消息还是缓存之后批量推送。如果为了避免 consumer 崩溃而采用    
较低的推送速率，将可能导致一次只推送较少的消息而造成浪费。Pull 模式下，  
consumer 就可以根据自己的消费能力去决定这些策略。   
Pull 有个缺点是，如果 broker 没有可供消费的消息，将导致 consumer 不断在循           
环中轮询，直到新消息到 t 达。为了避免这点，Kafka 有个参数可以让 consumer    
阻塞知道新消息到达(当然也可以阻塞知道消息的数量达到某个特定的量这样就可        
以批量发送)。

###讲讲 kafka 维护消费状态跟踪的方法
大部分消息系统在 broker 端的维护消息被消费的记录：一个消息被分发到   
consumer 后 broker 就马上进行标记或者等待 customer 的通知后进行标记。这   
样也可以在消息在消费后立马就删除以减少空间占用。    
但是这样会不会有什么问题呢？如果一条消息发送出去之后就立即被标记为消费
过的，一旦 consumer 处理消息时失败了（比如程序崩溃）消息就丢失了。为了    
解决这个问题，很多消息系统提供了另外一个个功能：当消息被发送出去之后仅
仅被标记为已发送状态，当接到 consumer 已经消费成功的通知后才标记为已被    
消费的状态。这虽然解决了消息丢失的问题，但产生了新问题，首先如果 consumer   
处理消息成功了但是向 broker 发送响应时失败了，这条消息将被消费两次。第二    
个问题时，broker 必须维护每条消息的状态，并且每次都要先锁住消息然后更改     
状态然后释放锁。这样麻烦又来了，且不说要维护大量的状态数据，比如如果消
息发送出去但没有收到消费成功的通知，这条消息将一直处于被锁定的状态，  
Kafka 采用了不同的策略。Topic 被分成了若干分区，每个分区在同一时间只被一      
个 consumer 消费。这意味着每个分区被消费的消息在日志中的位置仅仅是一个    
简单的整数：offset。这样就很容易标记每个分区消费状态就很容易了，仅仅需要     
一个整数而已。这样消费状态的跟踪就很简单了。          
这带来了另外一个好处：consumer 可以把 offset 调成一个较老的值，去重新消        
费老的消息。这对传统的消息系统来说看起来有些不可思议，但确实是非常有用     
的，谁规定了一条消息只能被消费一次呢？


###Zookeeper 对于 Kafka 的作用是什么？
Zookeeper 是一个开放源码的、高性能的协调服务，它用于 Kafka 的分布式应用。   
Zookeeper 主要用于在集群中不同节点之间进行通信        
在 Kafka 中，它被用于提交偏移量，因此如果节点在任何情况下都失败了，它都     
可以从之前提交的偏移量中获取  
除此之外，它还执行其他活动，如: leader 检测、分布式同步、配置管理、识别新       
节点何时离开或连接、集群、节点实时状态等等。
###数据传输的事务定义有哪三种？
和 MQTT 的事务定义一样都是 3 种。       
（1）最多一次: 消息不会被重复发送，最多被传输一次，但也有可能一次不传输   
（2）最少一次: 消息不会被漏发送，最少被传输一次，但也有可能被重复传输. （3）精确的一次（Exactly once）: 不会漏传输也不会重复传输,每个消息都传输      
被一次而且仅仅被传输一次，这是大家所期望的
###Kafka 判断一个节点是否还活着有那两个条件？
（1）节点必须可以维护和 ZooKeeper 的连接，Zookeeper 通过心跳机制检查每个节点的连接         
（2）如果节点是个 follower,他必须能及时的同步 leader 的写操作，延时不能太

###Kafka 与传统 MQ 消息系统之间有三个关键区别
(1).Kafka 持久化日志，这些日志可以被重复读取和无限期保留       
(2).Kafka 是一个分布式系统：它以集群的方式运行，可以灵活伸缩，在内部通过复制数据提升容错能力和高可用性        
(3).Kafka 支持实时的流式处理
###讲一讲 kafka 的 ack 的三种机制
request.required.acks 有三个值 0 1 -1(all)      
0:生产者不会等待 broker 的 ack，这个延迟最低但是存储的保证最弱当 server 挂掉的时候就会丢数据。      
1：服务端会等待 ack 值 leader 副本确认接收到消息后发送 ack 但是如果 leader      
挂掉后他不确保是否复制完成新 leader 也会导致数据丢失。     
-1(all)：服务端会等所有的 follower 的副本受到数据后才会受到 leader 发出的       
ack，这样数据不会丢失

###如何控制消费的位置
kafka 使用 seek(TopicPartition, long)指定新的消费位置。用于查找服务器保留       
的最早和最新的 offset 的特殊的方法也可用（seekToBeginning(Collection) 和      
seekToEnd(Collection)）

###kafka 分布式（不是单机）的情况下，如何保证消息的顺序消费?
Kafka 分布式的单位是 partition，同一个 partition 用一个 write ahead log 组织，       
所以可以保证 FIFO 的顺序。不同 partition 之间不能保证顺序。但是绝大多数用       
户都可以通过 message key 来定义，因为同一个 key 的 message 可以保证只发       
送到同一个 partition。        
Kafka 中发送 1 条消息的时候，可以指定(topic, partition, key) 3 个参数。       
partiton 和 key 是可选的。如果你指定了 partition，那就是所有消息发往同 1 个 partition，就是有序的。并且在消费端，Kafka 保证，1 个 partition 只能被 1 个 consumer 消费。或者你指定 key（比如 order id），具有同 1 个 key 的      
所有消息，会发往同 1 个 partition。

###kafka 的高可用机制是什么？
这个问题比较系统，回答出 kafka 的系统特点，leader 和 follower 的关系，消息       
读写的顺序即可。        
https://www.cnblogs.com/qingyunzong/p/9004703.html      
https://www.tuicool.com/articles/BNRza2E        
https://yq.aliyun.com/articles/64703

###kafka 如何减少数据丢失
https://www.cnblogs.com /huxi2b/p/6056364.html

###kafka 如何不消费重复数据？比如扣款，我们不能重复的扣。
其实还是得结合业务来思考，我这里给几个思路：  
比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入     
了，update 一下好吧。  
比如你是写 Redis，那没问题了，反正每次都是 set，天然幂等性。
比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据     
的时候，里面加一个全局唯一的 id，类似订单 id 之类的东西，然后你这里消费     
到了之后，先根据这个 id 去比如 Redis 里查一下，之前消费过吗？如果没有消       
费过，你就处理，然后这个 id 写 Redis。如果消费过了，那你就别处理了，保        
证别重复处理相同的消息即可。      
比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束     
了，重复数据插入只会报错，不会导致数据库中出现脏数据。

#rabbitmq
###producer  exchanges  queues   consumer
###四种交换机：
i. 直连交换机，Direct exchange：带路由功能的交换机，根据routing_key（消息发送的时候需要指定）直接绑定到队列，
⼀个交换机也可以通过过个routing_key绑定多个队列。
ii. 扇形交换机，Fanout exchange：⼴播消息。
iii. 主题交换机，Topic exchange：发送到主题交换机上的消息需要携带指定规则的routing_key，主题交换机会根据这个规
则将数据发送到对应的(多个)队列上。
iv. ⾸部交换机，Headers exchange：⾸部交换机是忽略routing_key的⼀种路由⽅式。路由器和交换机路由的规则是通过
Headers信息来交换的，这个有点像HTTP的Headers。将⼀个交换机声明成⾸部交换机，绑定⼀个队列的时候，定义⼀
个Hash的数据结构，消息发送的时候，会携带⼀组hash数据结构的信息，当Hash的内容匹配上的时候，消息就会被写⼊队
列。

###rabbitmq队列与消费者的关系？
a. ⼀个队列可以绑定多个消费者；    
b. 消息分发：若该队列⾄少有⼀个消费者订阅，消  息将以循环（round-robin）的⽅式发送给消费者。每条消息只会分发给⼀个    
订阅的消费者（前提是消费者能够正常处理消息并进⾏确认）。     
### rabbitmq交换器种类。
1. fanout交换器：它会把所有发送到该交换器的消息路由到所有与该交换器绑定的队列中；
2. direct交换器：direct类型的交换器路由规则很简单，它会把消息路由到哪些BindingKey和RoutingKey完全匹配的队列中；
3. topic交换器：匹配规则⽐direct更灵活。
4. headers交换器：根据发送消息内容的headers属性进⾏匹配（由于性能很差，不实⽤）。

#zookeeper
###介绍下ZooKeeper
ZooKeeper 是一个开放源码的分布式协调服务，它是集群的管理者分布式应用程序可以基于 Zookeeper 实现诸如数据发布/订阅、负载均衡、命名     
服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等功能,提供了文件系统和通知机制               
Zookeeper 保证了如下分布式一致性特性：        
1、顺序一致性         
2、原子性       
3、单一视图      
4、可靠性       
5、实时性（最终一致性）

###ZAB 协议？  
ZAB 协议是为分布式协调服务 Zookeeper 专门设计的一种支持崩溃恢复的原子广播协议。         
ZAB 协议包括两种基本的模式：崩溃恢复和消息广播。      
当整个 zookeeper 集群刚刚启动或者 Leader 服务器宕机、重启或者网络故障导           
致不存在过半的服务器与 Leader 服务器保持正常通信时，所有进程（服务器）进            
入崩溃恢复模式，首先选举产生新的 Leader 服务器，然后集群中 Follower 服务       
器开始与新的 Leader 服务器进行数据同步，当集群中超过半数机器与该 Leader             
服务器完成数据同步之后，退出恢复模式进入消息广播模式，Leader 服务器开始                 
接收客户端的事务请求生成事物提案来进行事务请求处理。      

###zookeeper的⼯作原理
特点：   
1、能够⽤在⼤型分布式系统中；   
2、具有⼀致性、可⽤性、容错性，不会因为⼀个节点的错误⽽崩溃；     
3、⽤途：⽤户⼤型分布式系统，作协调服务⻆⾊；     
1、分布式锁应⽤：通过对集群进⾏master选举，来解决分布式系统中的单点故障（⼀主n从，主挂全挂）。     
2、协调服务；     
3、注册中⼼；     
4、原理：       
术语：     
数据结构Znode：zookeeper数据采⽤树形层次结构，和标准⽂件系统⾮常相似，树中每个节点被称为Znode；       
通知机制Watcher：zookeeper可以为所有的读操作（exists()、getChilden()及getData()）设置watch，watch事件是⼀次       
性出发器，当watch的对象状态发⽣改变时，将会触发次对象上watch所对应的事件。watch事件将被异步的发送给客户端，并且zookeeper为       
watch机制提供了有序的⼀致性保证。     
基本流程：分布式锁应⽤场景           
1、传统的⼀主n从分布式系统，容易发⽣单点故障，传统解决⽅式是增加⼀个备⽤节点，定期给主节点发送Ping包，主节点回复     
ack，但是如果⽹络原因ack丢失，那么会出现两个主节点，造成数据混乱。        
2、zookeeper的引⼊可以管理两个主节点，其中挂了⼀个，会将另外⼀个作为新的主节点，挂的节点回来时担任备⽤节点；         
![img.png](../面试Img/img_3.png)

###cap理论
1、概念：⼀个分布式系统最多只能同时满⾜⼀致性（Consistency）、可⽤性（Availability）和分区容错性（Partition tolerance）这
三项中的两项。
2、⼀致性：更新操作成功并返回客户端完成后，所有节点在同⼀时间的数据完全⼀致，所以，⼀致性，说的就是数据⼀致性。
3、可⽤性：服务⼀直可⽤，⽽且是正常响应时间。
4、分区容错性：分布式系统在遇到某节点或⽹络分区故障的时候，仍然能够对外提供满⾜⼀致性和可⽤性的服务。
###⼆段式满⾜cap理论的哪两个理论
两阶段提交协议在正常情况下能保证系统的强⼀致性，但是在出现异常情况下，当前处理的操作处于错误状态，需要管理员⼈⼯⼲预
解决，因此可⽤性不够好，这也符合CAP协议的⼀致性和可⽤性不能兼得的原理。
###线程池的参数配置，为什么java官⽅提供⼯⼚⽅法给线程池
![img.png](../面试Img/img_4.png)
![img.png](../面试Img/img_5.png)
⼯⼚⽅法作⽤：ThreadPoolExecutor类就是Executor的实现类，但ThreadPoolExecutor在使⽤上并不是那么⽅便，在实例化时需      
要传⼊很多个参数，还要考虑线程的并发数等与线程池运⾏效率有关的参数，所以官⽅建议使⽤Executors⼯程类来创建线程池对象。      

###什么是中间件？
中间件是处于操作系统和应用程序之间软件，使用时旺旺是一组中间件集成在一起，构成一个平台（开发平台+运行平台），在这组中间件中必须要有一个通信中间件，即中间件=平台+通信。该定义也限定了只有勇于分布式系统中才能称为中间件
主要分类：远程过程调用、面向消息的中间件、对象请求代理、事物处理监控。

###ThreadLock用过没有,说说它的作用?
```
ThreadLock为本地线程，为每一个线程提供一个局部变量，也就是说只有当前线层可以访问，是线程安全的。原理：为每一个线程分配一个对象来工作，并不是由ThreadLock来完成的，而是需要在应用层面保证的，ThreadLock只是起到了一个容器的作用。原理为ThreadLock的set()跟get()方法。
实现原理：
public void set(T value) {
Thread t = Thread.currentThread();
ThreadLocalMap map = getMap(t);
if (map != null)
map.set(this, value);
else
createMap(t, value);
}
public T get() {
Thread t = Thread.currentThread();
ThreadLocalMap map = getMap(t);
if (map != null) {
ThreadLocalMap.Entry e = map.getEntry(this);
if (e != null)
return (T)e.value;
}
return setInitialValue();
}
```
ThreadLocal 内部实现机制： 
每个线程内部都会维护一个类似 HashMap 的对象，称为 ThreadLocalMap，里边会包含若干了 Entry（K-V 键值对），相应的线程被称为这些 Entry 的属主线程；    
Entry 的 Key 是一个 ThreadLocal 实例，Value 是一个线程特有对象。Entry 的作用即是：为其属主线程建立起一个 ThreadLocal 实例与一个线程特有对象之间的对应关系；  
Entry 对 Key 的引用是弱引用；Entry 对 Value 的引用是强引用。      

    

###分布式事务解决方案?
(1)什么是分布式事务？        
a.什么情况下需要用到分布式事务？       
a)当本地数据库断电、机器宕机、网络异常、消息丢失、消息乱序、数据错误、不可靠TCP、存储数据丢失、其他异常等需要用到分布式事务。       
b)例如：当本地事务数据库断电的这种秦光，如何保证数据一致性？数据库由连个文件组成的，一个数据库文件和一个日志文件，数据库任何写入操作都要先写日志，在操作前会吧日志文件写入磁盘，那么断电的时候及时才做没有完成，在重启数据库的时候，数据库会根据当前数据情况进行undo回滚活redo前滚，保证了数据的强一致性。      
c)分布式理论：当单个数据库性能产生瓶颈的时候，可能会对数据库进行分区（物理分区），分区之后不同的数据库不同的服务器上	，此时单个数据库的ACID不适应这种清苦啊，在此集群环境下很难达到集群的ACID，甚至效率性能大幅度下降，重要的是再很难扩展新的分区了。此时就需要引用一个新的理论来使用这种集群情况：CAP定理        
d)CAP定理:由加州肚饿伯克利分销Eric Brewer教授提出，指出WEB服务无法同时满足3个属性：        
a.一致性：客户端知道一系列的操作都会同时发生（生效）     
b.可用性：每个操作都必须以可预期的响应结束      
c.分区容错性：及时出现单组件无法可用，操作依然可以完成。       
具体的将在分布式系统中，在任何数据库设计中，一个WEB应        
至多只能同时支持上面两个属性。设计人员必须在一致性和可用        
性之间做出选择。        
e)BASE理论：分布式系统中追求的是可用性，比一致性更加重要，BASE理论来实现高可用性。核心思想是：我们无法做到羟乙酯，单每个应用都可以根据自身的业务特点，采用适当的方式使系统达到最终一致性。      
f)数据库事务特性：           
i.**原子性**       
ii.**一致性**      
iii.**隔离性**     
iv.**持久性**      
(2)分布式系统中，实现分布式事务的解决方案：     
a.两阶段提交2PC      
b.补偿事务TCC       
c.本地消息表（异步确保）       
d.MQ事务消息        
e.Sagas事务模型     

###sql语句优化会不会,说出你知道的?
(1)避免在列上做运算，可能会导致索引失败           
(2)使用join时应该小结果集驱动大结果集，同时把复杂的join查询拆分成多个query，不然join越多表，会导致越多的锁定和堵塞。        
(3)注意like模糊查询的使用，避免使用%%     
(4)不要使用select * 节省内存        
(5)使用批量插入语句，节省交互        
(6)Limit基数比较大时，使用between  and       
(7)不要使用rand函数随机获取记录     
(8)避免使用null，建表时，尽量设置not nul，提高查询性能      
(9)不要使用count（id），应该使用count（*）       
(10)不要做无谓的排序，尽可能在索引中完成排序        
(11)From语句中一定不要使用子查询        
(12)使用更多的where加以限制，缩小查找范围       
(13)合理运用索引      
(14)使用explain查看sql性能      


###红黑树原理？   
红黑树的性质：红黑树是一个二叉搜索树。在每个节点增加了一个存储位记录节点的颜色，可以是RED，也可以是BLACK，通过任意一条从根到叶子简单路径上颜色的约束，红黑树保证最长路径不超过最短路径的两倍，加以平衡。性质如下：       
i.每个节点颜色不是黑色就是红色        
ii.根节点的颜色是黑色的       
iii.如果一个节点是红色，那么他的两个子节点就是黑色的，没有持续的红节点       
iv.对于每个节点，从该节点到其后代叶节点的简单路径上，均包含相同数目的黑色节点。  

###说说Java中异常的分类。    
答：异常分类：     
Throwable -> Error,Exception        
Error:严重问题，例如内存溢出       
Exception ->运行时异常： RuntimeException，编译时异常       
AWTError   

###怎么给List排序？
答：List 如何排序：
①：使用  Collections.sort 默认正序，可以传第二个参数自定义排序
②：自定义bean实现 Comparable 接口。
③： 实现Comparator接口自定义比较器 

###讲一下模版模式和策略模式的区别？
答：模板方法模式的主要思想：定义一个算法流程，将一些特定步骤的具体实现、延迟到子类。使得可以在不改变算法流程的情况下，通过不同的子类、来实现“定制”流程中的特定的步骤。    
策略模式的主要思想：使不同的算法可以被相互替换，而不影响客户端的使用。


#redis
###redis各种应⽤场景
a. 更多的数据结构；    
b. 可持久化；    
c. 计数器；     
d. 发布-订阅功能；    
e. 事务功能；    
f. 过期回调功能；     
g. 队列功能；    
h. 排序、聚合查询功能。     

### redis持久化机制    
a. RDB：快照形式是直接把内存中的数据保存到⼀个 dump ⽂件中，定时保存，保存策略。（会丢数据）     
b. AOF：把所有的对Redis的服务器进⾏修改的命令都存到⼀个⽂件⾥，命令的集合。（影响性能）     

###Redis 缓存雪崩？击穿？穿透？
缓存雪崩：缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数 据库短时间内承受大量请求而崩掉。 
缓存击穿：key 对应的数据存在，但在 redis 中过期，此时若有大量并发请求过来，这 些请求发现缓存过期一般都会从后端 DB 加载数据并回设到缓存，这个时候大并发的请求 可能会瞬间把后端 DB 压垮。 
缓存穿透：key 对应的数据在数据源并不存在，每次针对此 key 的请求从缓存获取不 到，请求都会到数据源，从而可能压垮数据源。比如用一个不存在的用户 id 获取用户信 息，不论缓存还是数据库都没有，若黑客利用此漏洞进行攻击可能压垮数据库。

###缓存和数据库双写⼀致性问题解决⽅案
一致性方案:   
前提是对数据有强⼀致性要求，不能放缓存； 
只能降低不⼀致发⽣的概率，⽆法完全避免； 
只能保证最终⼀致性。  
1）采⽤正确的更新策略，先更新数据库，再删缓存    
2）可能存在删除缓存失败的问题，提供⼀个补偿措施：如利⽤消息队列    
缓存雪崩解决⽅案:   
（⼤并发项⽬，流量在⼏百万）    
-利⽤互斥锁：会使吞吐量下降    
-给缓存加失效时间：随机值，避免集体失效    
-双缓存        
缓存穿透解决⽅案:      
（⼤并发项⽬，流量在⼏百万）          
-利⽤互斥锁            
-采⽤异步更新策略，⽆论Key是否取到值都直接返回           
-提供⼀个能迅速判断请求是否有效的拦截机制（布隆过滤器）            
缓存并发竞争解决⽅案:          
-不要求顺序时，准备⼀个分布式锁，同时去抢锁，然后在set操      
作。    
-要求顺序时，在数据写⼊数据库时，需要保存⼀个时间戳。      
-利⽤队列，将set操作变成串⾏访问。     

### Redis的内存回收机制有哪些？
1. 定时过期：每个设置过期时间的key都需要创建⼀个定时器，到过期
   时间就会⽴即清除。该策略可以⽴即清除过期的数据，对内存很友好；但是会占
   ⽤⼤量的CPU资源去处理过期的数据，从⽽影响缓存的响应时间和吞吐量。
2. 惰性过期：只有当访问⼀个key时，才会判断该key是否已过期，过期
   则清除。该策略可以最⼤化地节省CPU资源，却对内存⾮常不友好。极端情况可
   能出现⼤量的过期key没有再次被访问，从⽽不会被清除，占⽤⼤量内存。
3. 定期过期：每隔⼀定的时间，会扫描⼀定数量的数据库的expires字
   典中⼀定数量的key，并清除其中已过期的key。该策略是前两者的⼀个折中⽅
   案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使
   得CPU和内存资源达到最优的平衡效果。(expires字典会保存所有设置了过期时
   间的key的过期时间数据，其中，key是指向键空间中的某个键的指针，value是
   该键的毫秒精度的UNIX时间戳表示的过期时间。键空间是指该Redis集群中保存
   的所有键。)


###淘汰策略
volatile-lru：设置了过期时间的key使用LRU算法淘汰；     
allkeys-lru：所有key使用LRU算法淘汰；      
volatile-lfu：设置了过期时间的key使用LFU算法淘汰；     
allkeys-lfu：所有key使用LFU算法淘汰；      
volatile-random：设置了过期时间的key使用随机淘汰；     
allkeys-random：所有key使用随机淘汰；         
volatile-ttl：设置了过期时间的key根据过期时间淘汰，越早过期越早淘汰；      
noeviction：默认策略，当内存达到设置的最大值时，所有申请内存的操作都会报错(如set,lpush等)，只读操作如get命令可以正常执行；     

###redis和MQ如何平滑的扩容与缩容？
答：MQ的消息是存放在内存或者磁盘中的，在缩减集群数量时，必须要迁移节点的数据。增加节点时，要重新配置集群。这么看来是无法平滑缩容和扩容的。  
###MQ的消息生产比消费速度快得多，有什么解决方案吗？
生产消息比消费速度快得多，这个本身是没问题的，因为MQ的一个作用就是削峰。   
如果要提高消费速度，可以增加多个消费者 

#springCloud
###Eureka的保护机制
Eureka Server的⾃我保护机制会检查最近15分钟内所有Eureka    
Client正常⼼跳的占⽐，如果低于85%就会被触发。      
我们如果在Eureka Server的管理界⾯发现如下的红⾊内容，就说明      
已经触发了⾃我保护机制。      
###多个消费者调⽤同⼀接⼝，eruka默认的分配⽅式是什么
a. RoundRobinRule:轮询策略，Ribbon以轮询的⽅式选择服务器，这个是默认值。所以示例中所启动的两个服务会被循环访问;
b. RandomRule:随机选择，也就是说Ribbon会随机从服务器列表中选择⼀个进⾏访问;
c. BestAvailableRule:最⼤可⽤策略，即先过滤出故障服务器后，选择⼀个当前并发请求数最⼩的;
d. WeightedResponseTimeRule:带有加权的轮询策略，对各个服务器响应时间进⾏加权处理，然后在采⽤轮询的⽅式来获取相
应的服务器;
e. AvailabilityFilteringRule:可⽤过滤策略，先过滤出故障的或并发请求⼤于阈值⼀部分服务实例，然后再以线性轮询的⽅式从
过滤后的实例清单中选出⼀个;
f. ZoneAvoidanceRule:区域感知策略，先使⽤主过滤条件（区域负载器，选择最优区域）对所有实例过滤并返回过滤后的实例
清单，依次使⽤次过滤条件列表中的过滤条件对主过滤条件的结果进⾏过滤，判断最⼩过滤数（默认1）和最⼩过滤百分⽐（默
认0），最后对满⾜条件的服务器则使⽤RoundRobinRule(轮询⽅式)选择⼀个服务器实例。

###熔断的原理，以及如何恢复？
服务的健康状况 = 请求失败数 / 请求总数.
熔断器开关由关闭到打开的状态转换是通过当前服务健康状况和设定阈值⽐较决定的.
1. 当熔断器开关关闭时, 请求被允许通过熔断器. 如果当前健康状况⾼于设定阈值, 开关继续保持关闭. 如果当前健康状况低于设定
   阈值, 开关则切换为打开状态.
2. 当熔断器开关打开时, 请求被禁⽌通过.
3. 当熔断器开关处于打开状态, 经过⼀段时间后, 熔断器会⾃动进⼊半开状态, 这时熔断器只允许⼀个请求通过. 当该请求调⽤成功
   时, 熔断器恢复到关闭状态. 若该请求失败, 熔断器继续保持打开状态, 接下来的请求被禁⽌通过.
   熔断器的开关能保证服务调⽤者在调⽤异常服务时, 快速返回结果, 避免⼤量的同步等待. 并且熔断器能在⼀段时间后继续侦测请求执
   ⾏结果, 提供恢复服务调⽤的可能.
4. 假如A服务可以调⽤B服务，A服务也可以调⽤C服务，如果B服务挂了，⼤量的A-B请求过来，Hystrix如何防⽌服务雪崩（Hystrix
   的隔离流程）？
   在⼀个⾼度服务化的系统中,我们实现的⼀个业务逻辑通常会依赖多个服务
5. 调⽤三个依赖服务会共享商品详情服务的线程池. 如果其中的商品评论服务不可⽤, 就会出现线程池⾥所有线程都因等待响应⽽被
   阻塞, 从⽽造成服务雪崩
6. Hystrix通过将每个依赖服务分配独⽴的线程池进⾏资源隔离, 从⽽避免服务雪崩.
   如下图所示, 当商品评论服务不可⽤时, 即使商品服务独⽴分配的20个线程全部处于同步等待状态,也不会影响其他依赖服务的调⽤

###feign如何实现负载均衡，与Ribbon的负载均衡有什么区别？
答： Feign 一般用 Ribbon 来实现负载均衡。
与 Ribbon 负载均衡的区别？我觉得2个是不一样的东西吧，Feign 已经包含了 Ribbon，需要配合使用，一般生产环境用的是 Spring Cloud 技术来整合的，当然也可以用其他技术来替代。   
Feign 作为客户端 
Ribbon 作为负载均衡   
Eureka 作为注册中心   
Zuul 作为网关   
Security 作为安全 OAuth 2 认证    
首先得知道 Feign 和 Ribbon 是什么，然后具体怎么实现参考小马哥微服务课程，也可以看官网  
Feign：申明式 Web 服务客户端 
申明式：接口声明、Annotation 驱动  
Web 服务：HTTP 的方式作为通讯协议   
客户端：用于服务调用的存根   
假设，有一个Java 接口 UserService, Feign 可以将其声明它是以 HTTP 方式调用的。  
Ribbon：客户端负载均衡器，可以对 HTTP 和 TCP 客户端的行为进行控制。      





###讲一下主从同步**
https://blog.csdn.net/honglei915/article/details/37565289

###为什么需要消息系统，mysql 不能满足需求吗？
1.解耦：   
允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。 
2.冗余：   
消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据 
丢失风险。许多消息队列所采用的”插入-获取-删除”范式中，在把一个消息从队       
列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保 
你的数据被安全的保存直到你使用完毕。  
3.扩展性：  
因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，    
只要另外增加处理过程即可。   
4.灵活性 & 峰值处理能力： 
在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不 
常见。如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪 
费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负 
荷的请求而完全崩溃。  
5.可恢复性：     
系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合 
度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复 
后被处理。   
6.顺序保证：     
在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，        
并且能保证数据会按照特定的顺序来处理。（Kafka 保证一个 Partition 内的消    
息的有序性）  
7.缓冲：       
有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度 
不一致的情况。     
8.异步通信：     
很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允 
许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放 
多少，然后在需要的时候再去处理它们。  
    
###消费者如何不自动提交偏移量，由应用提交？     
将 auto.commit.offset 设为 false，然后在处理一批消息后 commitSync() 或者        
异步提交 commitAsync()      
即：  
ConsumerRecords<> records = consumer.poll();    
for (ConsumerRecord<> record : records){        
。。。 
tyr{    
    
consumer.commitSync()
}   
。。。 
}   
###消费者故障，出现活锁问题如何解决？
出现“活锁”的情况，是它持续的发送心跳，但是没有处理。为了预防消费者在 
这种情况下一直持有分区，我们使用 max.poll.interval.ms 活跃检测机制。 在此    
基础上，如果你调用的 poll 的频率大于最大间隔，则客户端将主动地离开组，以 
便其他消费者接管该分区。 发生这种情况时，你会看到 offset 提交失败（调用    
commitSync（）引发的 CommitFailedException）。这是一种安全机制，保障  
只有活动成员能够提交 offset。所以要留在组中，你必须持续调用 poll。
消费者提供两个配置设置来控制 poll 循环：
max.poll.interval.ms：增大 poll 的间隔，可以为消费者提供更多的时间去处理返
回的消息（调用 poll(long)返回的消息，通常返回的消息都是一批）。缺点是此值
越大将会延迟组重新平衡。    
max.poll.records：此设置限制每次调用 poll 返回的消息数，这样可以更容易的     
预测每次 poll 间隔要处理的最大值。通过调整此值，可以减少 poll 间隔，减少重 
新平衡分组的      
对于消息处理时间不可预测地的情况，这些选项是不够的。 处理这种情况的推荐        
方法是将消息处理移到另一个线程中，让消费者继续调用 poll。 但是必须注意确     
保已提交的 offset 不超过实际位置。另外，你必须禁用自动提交，并只有在线程
完成处理后才为记录手动提交偏移量（取决于你）。 还要注意，你需要 pause 暂        
停分区，不会从 poll 接收到新消息，让线程处理完之前返回的消息（如果你的处     
理能力比拉取消息的慢，那创建新线程将导致你机器内存溢出）。       
  













